---
title: 'Case Study: IRIS Classification'
output:
  html_notebook: default
  html_document: default
  pdf_document: default
---

### Hello World of Machine Learning
This is a good project because it is so well understood.

- Attributes are numeric so you have to figure out how to load and handle data.
- It is a classification problem, allowing you to practice with perhaps an easier type of supervised learning algorithms.
- It is a mutli-class classification problem (multi-nominal) that may require some specialized handling.
- It only has 4 attribute and 150 rows, meaning it is small and easily fits into memory.
- It gives an opportunity to apply many Machine Learning algorithms, to compare and contrast

---

### Installing the required packages
We need to load a few important packages first to begin our analysis

#### *CARET Package* 
The caret package provides a consistent interface into hundreds of machine learning algorithms and provides useful convenience methods for data visualization, data resampling, model tuning and model comparison, among other features. It’s a must have tool for machine learning projects in R. [Refer][3]

#### *TIDYR Package:*  
Is a new package that makes it easy to “tidy” your data. Tidy data is data that’s easy to work with: it’s easy to munge (*with dplyr*), visualise (*with ggplot2 or ggvis*) and model (with R’s hundreds of modelling packages). The two most important properties of tidy data are:

- Each column is a variable.
- Each row is an observation.

Arranging your data in this way makes it easier to work with because you have a consistent way of referring to variables (as column names) and observations (as row indices).
[Refer][2]

```{r}
install.packages("caret")
install.packages("tidyr")
```

---

### Get the Data
#### *About the data set*
The Iris flower data set or Fisher's Iris data set is a multivariate data set introduced by the British statistician and biologist Ronald Fisher in his 1936 paper. This is a very famous and widely used dataset by everyone trying to learn machine learning and statistics. The data set consists of 50 samples from each of three species of Iris (Iris setosa, Iris virginica and Iris versicolor). Four features were measured from each sample: the length and the width of the sepals and petals, in centimetres. The fifth column is the species of the flower observed. For more history of this dataset read here [Wikipedia](https://en.wikipedia.org/wiki/Iris_flower_data_set)

---

#### *Load the dataset*
We are going to do the following

- Load the iris data directly from within R (*This dataset is so famous it comes with your R installation!*).
- Download and Load the data from a file. (*This is usually what you have to do for other problems*)
- Split the data into a training dataset and a testing dataset to perform machine learning (*This is a standard 2 way split in machine learning. We could also do a 3 way split: training, validation and testing*)

---

#### *Loading the data from within R*
```{r}
# Attach the dataset to the environment
data(iris)
# Get help on the data
help(iris)
# Rename the data
iris_dataset<-iris
# View the data
View(iris_dataset)
```

#### *Loading the data from external source*
In most cases you will work with, the data file is usually hosted somewhere on the internet which you might have to download and read the file into the R environment/memory before you can start working with it. It is also good practice to download the files from directly within your R script whenever possible because it makes your work more shareable and reproducible by others. The code below illustrates how this data is downloaded from the [UCI Machine Learning repository](https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data)

```{r}
# set the url for download
url<-"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data"
# set the filename and directory to download into
filename<-"./Data/iris.csv"
# Download the file
download.file(url=url, destfile = filename, method ="curl")
print("IRIS File downloaded")
```


Next we need to read the data from the file
```{r}
# Read the file into the R environment
iris_filedata<-read.csv(file = filename,header = FALSE,sep = ",")
```


Viewing the data from within the R console - Useful when dealing with larger datasets
```{r}
# View the top few rows of the data in R console
head(iris_filedata,7)
```


We see here that the data has no names for the columns (they are assigned names such as V1, V2, V3 etc). So next, we will assign names to these columns
```{r}
# Assigning meaningful column names
colnames(iris_filedata)<-c("Sepal.Length","Sepal.Width","Petal.Length","Petal.Width","Species")
head(iris_filedata,5)
```

---

#### *Splitting the Data into Training and Testing Sets*
This is one of the most important steps and concepts in Machine Learning. Before we do any meaningful work and learn from the dataset available to us, we need to split the dataset into `training set` and `testing set` and sometimes into a third `validation set`.

**TRAINING SET:** Is the `SEEN DATA` which is used to build and train the model. In classification problems such as this, we train the model using the classfication error rate: the percentage of incorrectly/correctly classified instances. We use the training data set to help us understand the data, select the appropriate model and determine model parameters.

**TESTING SET** This is the `UNSEEN DATA`. We build a model because we want to classify `new data`. We are also chiefly interested in the model performance(error rate) on this new data as it is more realistic estimate of the model fit in the real world.

**VALIDATION SET** Sometimes a part of the training set is split into the Validation Set to help us tune and optimize our models. It can be thought of as a Practice Testing set before we actually test the model using the TESTING SET

A good discussion of this topic can be found [here](https://stats.stackexchange.com/questions/19048/what-is-the-difference-between-test-set-and-validation-set)

```{r}
# Load the Caret package which allows us to partition the data
library(caret)
# We use the dataset to create a partition (80% training 20% testing)
index <- createDataPartition(iris_filedata$Species, p=0.80, list=FALSE)
# select 20% of the data for testing
testset <- iris_filedata[-index,]
# select 80% of data to train the models
trainset <- iris_filedata[index,]
```

Now that we have loaded and prepared our data for analysis, we are ready to move onto the next step which is `Exploring, Summarizing, Plotting and Understanding the Data`. 

---

### Explore the Data
*Since we are dealing here with a clean and small dataset we are able to avoid the step of `Cleaning the data` which typically consumes a majority of the data scientists' time. *

We explore the data to:

- Understand the data
- Summarize the data
- Clean and Prune the data
- Understand relationships between atrributes
- Think about and source other data which maybe useful in answering the question
- Get a preliminary feel for the types of models we think would best fit the data

----

#### Summarizing the Data

We begin by getting an idea of the attributes, dimensions and size of the data we are dealing with
```{r}
# Dimensions of the data
dim(trainset)
```

```{r}
# Structure of the data
str(trainset)
```

```{r}
# Summary of the data
summary(trainset)
```


```{r}
# Levels of the prediction column
levels(trainset$Species)
```

### *Visualization and Exploration via plots*
The advantage of a tool such as RStudio is that it allows a data scientist to creatively and quickly explore data via visualization. There are many powerful packages and tools in R such as `GGPLOT2`, `PLOTLY` etc which can be used to explore data as well as produce publishing quality plots to be used in reports and presentations. Here we will use some of these to explore and understand our dataset better

### Base R plots
We begin by using some base R plots to understand the distribution and attributes
```{r}
## Histogram
hist(trainset$Sepal.Width)
```

```{r}
## Scatter plot to check relationship between two attributes
plot(trainset$Petal.Length,trainset$Petal.Width)
```
```{r}
## Box plot to understand how the distribution varies for each attribute
par(mfrow=c(1,4))
  for(i in 1:4) {
  boxplot(trainset[,i], main=names(trainset)[i])
}
```

```{r}
## Another Box plot to understand the distribution for each attribute broken down by class
featurePlot(x=trainset[,1:4], y=trainset[,5], plot="box")
```

### Using ggplot2 and building better plots
ggplot2 is a very powerful package built on the concept of `"Grammar of Graphics (gg)"`. It allows you to **build** a plot following a particular syntax. It produces more aesthetically pleasing, more powerful plots than base graphics using more compact code for plot of similar complexity. You can read and understand more about ggplot [here](https://opr.princeton.edu/workshops/Downloads/2015Jan_ggplot2Koffman.pdf) and [here](http://tutorials.iq.harvard.edu/R/Rgraphics/Rgraphics.html).
A cheatsheet for ggplot is available [here](https://www.rstudio.com/wp-content/uploads/2015/03/ggplot2-cheatsheet.pdf)

Below we will plot some similar yet aesthetically pleasing plots using ggplot2
```{r}
# begin by loading the library
library(ggplot2)
```

```{r}
# Scatter plot
g <- ggplot(data=trainset, aes(x = Petal.Length, y = Petal.Width))
print(g)
```
  
```{r}
g <-g + 
    geom_point(aes(color=Species, shape=Species)) +
    xlab("Petal Length") +
    ylab("Petal Width") +
    ggtitle("Petal Length-Width")+
    geom_smooth(method="lm")

print(g)
```
```{r}
## Box Plot
box <- ggplot(data=trainset, aes(x=Species, y=Sepal.Length)) +
    geom_boxplot(aes(fill=Species)) + 
    ylab("Sepal Length") +
    ggtitle("Iris Boxplot") +
    stat_summary(fun.y=mean, geom="point", shape=5, size=4) 

print(box)
```

```{r}
library(ggthemes)
## Histogram
histogram <- ggplot(data=trainset, aes(x=Sepal.Width)) +
    geom_histogram(binwidth=0.2, color="black", aes(fill=Species)) + 
    xlab("Sepal Width") +  
    ylab("Frequency") + 
    ggtitle("Histogram of Sepal Width")+
    theme_economist()

print(histogram)
```

```{r}
## Faceting: Producing multiple charts in one plot
facet <- ggplot(data=trainset, aes(Sepal.Length, y=Sepal.Width, color=Species))+
    geom_point(aes(shape=Species), size=1.5) + 
    geom_smooth(method="lm") +
    xlab("Sepal Length") +
    ylab("Sepal Width") +
    ggtitle("Faceting") +
    theme_wsj() +
    facet_grid(. ~ Species) # Along rows

print(facet)

```

---

### Model Building

Now that we have loaded the data and explored it to get a basic understanding of the relationships between the attributes, we can move to the next step which is **`Model Building`**. 

> **The Problem**: *Given a set of data about the flowers (column 1 through 4) can we predict which of the 3 classes of flowers it belongs to.*

We will build and fit a few different models to the training set and try to learn from the `trainset` data. This is machine learning. We will later use the best model selected (or even a combination of models) to predict the classification for the `testset`. We will then measure how well our model is expected to perform in the real world.

---

### DECISION TREES
Decision Trees are a widely used set of algorithms used in Classification as well as Regression Problems in Data mining. Decision Trees classify observations by sorting them down the tree from the root node to the leaf node which provides the classification for the observation. Each node specifies a test on a particular attribute and each branch from that node represents one of the possible values for that test. These represent a form of supervised learning as trees can be first learnt using training observations and then be used to predict on the test set.

There are many decision tree algorithms available and vary by the method the trees are constructed and grown. Here we will use the simple `rpart` algorithm to classify our data set and predict

```{r}
library(caret)
set.seed(1000)
?rpart

# Fit the model
model.rpart<-train(x = trainset[,1:4],y = trainset[,5], method = "rpart",metric = "Accuracy")

```

```{r}
print(model.rpart)
```

Let us now plot the tree and see how the classification tree looks
```{r}
plot(model.rpart$finalModel)
text(model.rpart$finalModel)
```

Let us produce a prettier tree

```{r}
## We use the Rattle package to produce some pretty tree plots
# install.packages("rattle")
library(rattle)
# install.packages("rpart.plot")
fancyRpartPlot(model.rpart$finalModel)

```

Now we can check how the tree performs on our training data
```{r}
## Predictions on train dataset
pred<-table(predict(object = model.rpart$finalModel,newdata = trainset[,1:4],type="class"))
pred
```

```{r}
## Checking the accuracy using a confusion matrix by comparing predictions to actual classifications
confusionMatrix(predict(object = model.rpart$finalModel,newdata = trainset[,1:4],type="class"),trainset$Species)
```
Now let us predict on the test data set and see how the `rpart` model does
```{r}
## Checking accuracy on the testdata set we created initially
pred_test<-predict(object = model.rpart$finalModel,
                   newdata = testset[,1:4],
                   type="class")

confusionMatrix(pred_test,testset$Species)
```
Our accuracy on the test set is worse than our accuracy on the training set. This is usually to be expected. If the training set accuracy differs from the test set accuracy by a lot, usually it is an indication of model overfitting to the training set.

### RANDOM FORESTS
Produce a model which averages the predictions from many such classification trees.

From [Wikipedia](https://en.wikipedia.org/wiki/Random_forest)

> Random forests or random decision forests are an ensemble learning method for classification, regression and other tasks, that operate by constructing a multitude of decision trees at training time and outputting the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees. Random decision forests correct for decision trees' habit of overfitting to their training set.

Because of the standardization of the `CARET` package constructing fitting and verifying the performance of a `random forest` algorithm is very similar to the `rpart` algorithm we just saw

```{r}
library(caret)
## install.packages("rf")
set.seed(1000)
?randomForest

# Fit the model
model.rf<-train(x = trainset[,1:4],y = trainset[,5], method = "rf",metric = "Accuracy")
# Print the model
print(model.rf)

```
```{r}
## Verify the accuracy on the training set
pred<-predict(object = model.rf$finalModel,newdata = trainset[,1:4],type="class")
confusionMatrix(pred,trainset$Species)
```
We see the power of the random forest algorithm with the perfect accuracy of classification on the training set.

Let us now verify how it performs on the `testset` data in the real world
```{r}
## Performance on the test set
pred_test<-predict(object = model.rf$finalModel,newdata = testset[,1:4],type="class")
confusionMatrix(pred_test,testset$Species)
```
Even though we were able to improve our accuracy on the training set, on the test set we still are misclassifying two observations. We will next consider another class of Algorithm which we hope would improve our testset accuracy

### GRADIENT BOOSTING METHOD
This class of ML Algorithms uses a technique called `BOOSTING` where we still grow decision classification trees, but each successive tree is grown with an intent to classify the missclassified data from the previous tree correctly.

A very good discussion of this method is available here on [AnalyticsVidhya](https://www.analyticsvidhya.com/blog/2015/11/quick-introduction-boosting-algorithms-machine-learning/)

As before the method to build a model using this algorithm is very similar to the ones we used before. As in the previous cases a lot of the difference in actual implementation of the algo's comes from the various parameters used to optimize the algo's. `CARET` package also helps standardize the optimization steps such as [`CROSS VALIDATION`](https://lagunita.stanford.edu/c4x/HumanitiesScience/StatLearning/asset/cv_boot.pdf) ,[`HYPER PARAMETER TURNING`,`GRID SEARCH`](https://www.analyticsvidhya.com/blog/2016/02/complete-guide-parameter-tuning-gradient-boosting-gbm-python/) etc.

```{r}
library(caret)
## install.packages("gbm")
library(gbm)
set.seed(1000)

# Fit the model
model.gbm<-train(x = trainset[,1:4],y = trainset[,5], method = "gbm",metric = "Accuracy",verbose=FALSE)
# Print the model
print(model.gbm)

```
```{r}
summary(model.gbm$finalModel)
```


```{r}
## Verify the accuracy on the training set

pred<-predict(object = model.gbm,newdata = trainset[,1:4],type="prob")
confusionMatrix(pred,trainset$Species)
```



---

## References
 [1]:http://machinelearningmastery.com/machine-learning-in-r-step-by-step/
 [2]:https://blog.rstudio.org/2014/07/22/introducing-tidyr/ "Introduction to tidyr"
 [3]:http://topepo.github.io/caret/index.html "Introduction to caret"